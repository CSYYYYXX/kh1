{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda19887",
   "metadata": {},
   "source": [
    "\n",
    "# CAE-Transformer降阶模型——开尔文-亥姆霍兹不稳定性问题\n",
    "\n",
    "## 概述\n",
    "\n",
    "为有效降低使用CFD方法的设计成本和周期，近年来降阶模型得到了广泛的关注。对于复杂的可压缩流动，使用本征正交分解(POD)等线性方法进行流场降维，需要大量的模态才能保证流场重建的精度。已有研究表明，采用非线性降维方法能够有效减少所需模态数。卷积自编码器(CAE)是一种由编码器和解码器组成的神经网络，能够实现数据降维和重构，可看作是POD方法的非线性拓展。采用CAE进行流场数据的非线性降维，同时使用Transformer进行流场状态的时间演化。针对非定常可压缩流动，CAE-Transformer降阶模型能够在使用较少自由变量数的前提下获得较高的重构和预测精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39552eaf",
   "metadata": {},
   "source": [
    "## 模型架构\n",
    "\n",
    "CAE-Transformer降阶模型采用CAE网络对流场进行降维，提取流动数据的特征，将其压缩到编码器的隐藏空间中，再用Transformer网络通过注意力机制对隐藏空间的自由变量进行时间演化，得到流动其他时刻的自由变量，再通过CAE网络的解码器将演化的自由变量进行解码，重建得到相应时刻的流场流动数据。CAE-Transformer流动降阶模型的构造依赖于CAE网络的数据降维和Transformer网络的时间演化。与现有的POD/DMD等方法相比，使用CAE网络对流场数据进行非线性降维，同时使用Transformer网络对自由变量进行无方程演化，可以在保证流场降阶模型具备一定精度的情况下，得到更高的压缩比，提高流场预测的效率。\n",
    "\n",
    "+ 输入：输入一段时间的流场。\n",
    "+ 压缩：通过CAE的编码器对流场进行降维，提取高维时空流动特征。\n",
    "+ 演化：通过Transformer学习低维空间流场时空特征的演变，预测下一时刻。\n",
    "+ 重建：通过CAE的解码器将预测的流场低维特征恢复到高维空间。\n",
    "+ 输出：输出对下一时刻瞬态流场的预测结果。\n",
    "\n",
    "训练时，首先进行CAE网络的训练，训练完成之后使用CAE的编码器得到流场的低维特征，将此低维特征作为LSTM网络的数据集，进行LSTM网络的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5c41",
   "metadata": {},
   "source": [
    "![CAE_Transformer1.png](./images/CAE_Transformer1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7406dd",
   "metadata": {},
   "source": [
    "## 训练环境\n",
    "\n",
    "导入训练所需函数库，其中src包括数据集创建函数、网络模型和训练loss可视化函数。\n",
    "\n",
    "训练默认采用Mindspore框架的静态图模式(GRAPH)，在GPU(默认)或Ascend进行训练(单卡)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ba41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, set_seed, jit, data_sink\n",
    "from mindflow.utils import load_yaml_config\n",
    "\n",
    "from src import create_cae_dataset, CaeNet, plot_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3ba84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa53aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='cae net for kh')\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\", choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "                    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\")\n",
    "parser.add_argument(\"--save_graphs\", type=bool, default=False, choices=[True, False],\n",
    "                    help=\"Whether to save intermediate compilation graphs\")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./graphs\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"GPU\", choices=[\"GPU\", \"Ascend\"],\n",
    "                    help=\"The target device to run, support 'Ascend', 'GPU'\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0, help=\"ID of the target device\")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "                    save_graphs=args.save_graphs,\n",
    "                    save_graphs_path=args.save_graphs_path,\n",
    "                    device_target=args.device_target,\n",
    "                    device_id=args.device_id)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ca2c",
   "metadata": {},
   "source": [
    "## CAE网络训练参数设置\n",
    "\n",
    "从config.yaml文件里导入数据集、CAE模型和优化器的参数配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e0f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml_config(args.config_file_path)\n",
    "data_params = config[\"cae_data\"]\n",
    "model_params = config[\"cae_model\"]\n",
    "optimizer_params = config[\"cae_optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53d5ec",
   "metadata": {},
   "source": [
    "训练过程loss文件保存路径默认为optimizer_params[\"summary_dir\"]，权重参数保存在ckpt文件夹中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e34bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dir = optimizer_params[\"summary_dir\"]\n",
    "if not os.path.exists(summary_dir):\n",
    "    os.mkdir(summary_dir)\n",
    "ckpt_dir = os.path.join(summary_dir, 'ckpt')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505908fc",
   "metadata": {},
   "source": [
    "## 构建CAE网络\n",
    "\n",
    "CAE网络由六层卷积和极大池化构成编码器，由七层卷积和上采样构成解码器。使用MSELoss损失函数和Adam优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe1356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cae = CaeNet(model_params[\"data_dimension\"], model_params[\"conv_kernel_size\"], model_params[\"maxpool_kernel_size\"],\n",
    "             model_params[\"maxpool_stride\"], model_params[\"encoder_channels\"], model_params[\"decoder_channels\"],\n",
    "             model_params[\"channels_dense\"])\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "cae_opt = nn.Adam(cae.trainable_params(), optimizer_params[\"lr\"], weight_decay=optimizer_params[\"weight_decay\"])\n",
    "\n",
    "if use_ascend:\n",
    "    from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "    auto_mixed_precision(cae, 'O1')\n",
    "else:\n",
    "    loss_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacf783",
   "metadata": {},
   "source": [
    "## CAE网络数据集\n",
    "\n",
    "数据集下载地址：data_driven/cae-lstm/kh/dataset\n",
    "\n",
    "本案例数据集为二维开尔文-亥姆霍兹不稳定性问题的数值模拟结果，平行剪切流中的不稳定性叫做开尔文-亥姆霍兹不稳定性，坐标x和y范围为\\[-0.5, 0.5\\]，时间t范围为\\[0, 1.5\\]。共1786张流场快照，每张快照矩阵尺寸为(256, 256)。\n",
    "\n",
    "导入数据集之后进行数据下沉设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25786be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cae_dataset, _ = create_cae_dataset(data_params[\"data_path\"], data_params[\"batch_size\"])\n",
    "\n",
    "sink_process = data_sink(train_step, cae_dataset, sink_size=1)\n",
    "train_data_size = cae_dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771dfcdf",
   "metadata": {},
   "source": [
    "## CAE网络模型训练\n",
    "\n",
    "搭建forward_fn和train_step，开始CAE网络的训练，并将训练loss可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f16d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid:14003\n",
      "====================Start cae train=======================\n",
      "epoch: 1 train loss: 0.16278297 epoch time: 16.27s\n",
      "epoch: 2 train loss: 0.098297514 epoch time: 2.26s\n",
      "epoch: 3 train loss: 0.07453717 epoch time: 2.26s\n",
      "epoch: 4 train loss: 0.05944114 epoch time: 2.27s\n",
      "epoch: 5 train loss: 0.050014462 epoch time: 2.25s\n",
      "...\n",
      "epoch: 4396 train loss: 0.0009265681 epoch time: 2.23s\n",
      "epoch: 4397 train loss: 0.00071872084 epoch time: 2.22s\n",
      "epoch: 4398 train loss: 0.00075864815 epoch time: 2.22s\n",
      "epoch: 4399 train loss: 0.00073658983 epoch time: 2.22\n",
      "epoch: 4400 train loss: 0.0006535899 epoch time: 2.22s\n",
      "====================End cae train=======================\n"
     ]
    }
   ],
   "source": [
    "def forward_fn(data, label):\n",
    "    logits = cae(data)\n",
    "    loss = loss_fn(logits, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, cae_opt.parameters, has_aux=False)\n",
    "\n",
    "@jit\n",
    "def train_step(data, label):\n",
    "    loss, grads = grad_fn(data, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "        if all_finite(grads):\n",
    "            grads = loss_scaler.unscale(grads)\n",
    "    loss = ops.depend(loss, cae_opt(grads))\n",
    "    return loss\n",
    "\n",
    "print(f\"====================Start cae train=======================\")\n",
    "train_loss = []\n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    local_time_beg = time.time()\n",
    "    cae.set_train()\n",
    "    epoch_train_loss = 0\n",
    "    for _ in range(train_data_size):\n",
    "        epoch_train_loss = ops.squeeze(sink_process(), axis=())\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(f\"epoch: {epoch} train loss: {epoch_train_loss} epoch time: {time.time() - local_time_beg:.2f}s\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(cae, f\"{ckpt_dir}/cae_{epoch}.ckpt\")\n",
    "print(f\"=====================End cae train========================\")\n",
    "plot_train_loss(train_loss, summary_dir, optimizer_params[\"epochs\"], \"cae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a43727",
   "metadata": {},
   "source": [
    "## CAE流场重建结果\n",
    "\n",
    "在训练完CAE网络后，可运行cae_prediction.py查看CAE的训练结果，以判断是否继续进行Transformer网络的训练。\n",
    "\n",
    "下图分别为真实流场，CAE流场重建结果以及它们之间的误差曲线。其中前两个流场结果展现了流场中不同位置的密度随时间的变化情况，第三个误差曲线展现了CAE重建流场和真实流场label的平均相对误差随时间的变化情况。误差在大多数时间维持在0.015以下，满足流场重建精度需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c7619",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/true.gif\" title=\"cae_train_loss\" width=\"300\"/>\n",
    "    <img src=\"./images/cae.gif\" title=\"cae_prediction\" width=\"300\"/>\n",
    "    <img src=\"./images/cae_error.png\" title=\"cae_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e4826",
   "metadata": {},
   "source": [
    "## Transformer训练环境\n",
    "导入训练所需函数库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore as ms\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, set_seed, jit, data_sink\n",
    "from mindspore.train import CheckpointConfig, ModelCheckpoint\n",
    "from mindvision.engine.callback import LossMonitor\n",
    "\n",
    "from mindflow.utils import load_yaml_config\n",
    "from sympy import Q\n",
    "from src import create_transformer_dataset, plot_train_loss, Informer\n",
    "from cae_prediction import cae_prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "set_seed(42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"transformer net for KH\")\n",
    "parser.add_argument(\n",
    "    \"--mode\",\n",
    "    type=str,\n",
    "    default=\"GRAPH\",\n",
    "    choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_graphs\",\n",
    "    type=bool,\n",
    "    default=False,\n",
    "    choices=[True, False],\n",
    "    help=\"Whether to save intermediate compilation graphs\",\n",
    ")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./graphs\")\n",
    "parser.add_argument(\n",
    "    \"--device_target\",\n",
    "    type=str,\n",
    "    default=\"GPU\",\n",
    "    choices=[\"GPU\", \"Ascend\"],\n",
    "    help=\"The target device to run, support 'Ascend', 'GPU'\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--device_id\", type=int, default=0, help=\"ID of the target device\"\n",
    ")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "ms.set_context(device_target=\"GPU\")\n",
    "ms.set_context(mode=ms.PYNATIVE_MODE)\n",
    "use_ascend = context.get_context(attr_key=\"device_target\") == \"Ascend\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformer损失函数设置\n",
    "\n",
    "CustomWithLossCell是一个在 MindSpore 中自定义的损失计算处理损失函数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomWithLossCell(nn.Cell):\n",
    "    def __init__(self, backbone, loss_fn, args):\n",
    "        super(CustomWithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "        self.args = args\n",
    "\n",
    "    def construct(self, seq_x, seq_y):\n",
    "        cast = ops.Cast()\n",
    "\n",
    "        batch_x = cast(seq_x, ms.float32)\n",
    "        batch_y = cast(seq_y, ms.float32)\n",
    "\n",
    "        if self.args[\"padding\"] == 0:\n",
    "            dec_inp = ops.Zeros()(\n",
    "                (batch_y.shape[0], self.args[\"pred_len\"], batch_y.shape[-1]), ms.float32\n",
    "            )\n",
    "        else:\n",
    "            dec_inp = ops.Ones()(\n",
    "                (batch_y.shape[0], self.args[\"pred_len\"], batch_y.shape[-1]), ms.float32\n",
    "            )\n",
    "        dec_inp = cast(\n",
    "            ops.concat([batch_x[:, - self.args[\"label_len\"] : , :], dec_inp], axis=1),\n",
    "            ms.float32,\n",
    "        )\n",
    "\n",
    "        outputs = self._backbone(batch_x, dec_inp)\n",
    "        batch_y = batch_y[:, -self.args[\"pred_len\"] :, :]\n",
    "\n",
    "        return self._loss_fn(outputs, batch_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformer网络框架及训练设置\n",
    "\n",
    "首先导入Transformer模型数据集设置参数、Transformer模型和优化器参数设置。默认训练loss保存路径为optimizer_params[\"summary_dir\"]，权重参数保存在ckpt文件夹下。模型由多个编码器和解码器堆叠而成，使用MSELoss损失函数和Adam优化器。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbef106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare params\n",
    "config = load_yaml_config(args.config_file_path)\n",
    "data_params = config[\"transformer_data\"]\n",
    "model_params = config[\"transformer\"]\n",
    "optimizer_params = config[\"transformer_optimizer\"]\n",
    "\n",
    "# prepare summary file\n",
    "summary_dir = optimizer_params[\"summary_dir\"]\n",
    "ckpt_dir = os.path.join(summary_dir, \"ckpt\")\n",
    "\n",
    "# prepare model\n",
    "model = Informer(**model_params)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = nn.Adam(\n",
    "    model.trainable_params(),\n",
    "    optimizer_params[\"lr\"],\n",
    "    weight_decay=optimizer_params[\"weight_decay\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a08fc",
   "metadata": {},
   "source": [
    "## Transformer网络数据集加载与处理\n",
    "\n",
    "Transformer网络数据集由CAE的编码器得到，创建数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6e5aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "latent_true = cae_prediction(args.config_file_path)\n",
    "dataset, _ = create_transformer_dataset(\n",
    "    latent_true,\n",
    "    data_params[\"batch_size\"],\n",
    "    data_params[\"time_size\"],\n",
    "    data_params[\"latent_size\"],\n",
    "    data_params[\"time_window\"],\n",
    "    data_params[\"gaussian_filter_sigma\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab5ec56",
   "metadata": {},
   "source": [
    "## Transformer网络模型训练\n",
    "\n",
    "损失函数网络的构建、模型检查点回调函数的创建和trainer的初始化，开始Transformer网络的训练，并将训练loss可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b97708",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "time_now = time.time()\n",
    "loss_net = CustomWithLossCell(model, loss_fn, data_params)\n",
    "config = CheckpointConfig(save_checkpoint_steps=50, keep_checkpoint_max=2)\n",
    "ckpt_callback = ModelCheckpoint(\n",
    "     prefix=\"Informer\", directory=ckpt_dir, config=config\n",
    ")\n",
    "trainer = ms.Model(network=loss_net, optimizer=optimizer)\n",
    "for epoch in range(optimizer_params[\"epochs\"]):\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>Train_{epoch}<<<<<<<<<<<<<<<<<<<<\")\n",
    "    ts = time.time()\n",
    "    trainer.train(\n",
    "        1,\n",
    "        dataset,\n",
    "        callbacks=[\n",
    "            ckpt_callback,\n",
    "            LossMonitor(optimizer_params[\"lr\"], per_print_times=50),\n",
    "        ],\n",
    "    )\n",
    "    print(\"Train Time Cost:\", time.time() - ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aac646",
   "metadata": {},
   "source": [
    "## 预测流场结果可视化\n",
    "\n",
    "运行cae_transformer_prediction.py可查看CAE-Transfomer降阶模型的预测结果。\n",
    "\n",
    "下图分别为真实流场，CAE-Transformer网络的预测结果和相对应的平均相对误差。CAE-Transformer预测结果的误差比CAE重建的误差较大，是因为前者比后者多了Transformer的演化误差，但整个预测时间误差保持在0.02以下，满足流场预测精度需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ba22d",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/true2.gif\" title=\"cae_prediction\" width=\"300\"/>\n",
    "    <img src=\"./images/cae_lstm.gif\" title=\"cae_lstm_prediction\" width=\"300\"/>\n",
    "    <img src=\"./images/cae_lstm_error.png\" title=\"cae_lstm_error\" width=\"300\"/>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
